{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b039c9fc",
   "metadata": {},
   "source": [
    "INDEED job data search:\n",
    "Part 1:  project preparation. Build the basic url and get the web page, then show the structure of the website.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "772f6262",
   "metadata": {},
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ddbb22d",
   "metadata": {},
   "source": [
    "url = \"https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'lxml')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eafe45e4",
   "metadata": {},
   "source": [
    "title=\"oracle database\"\n",
    "location = \"Philadelphia\"\n",
    "num_entries = 20\n",
    "url = f\"https://www.indeed.com/jobs?q={title}&l={location}&start={num_entries}\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'lxml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20a0a7",
   "metadata": {},
   "source": [
    "Part: Build functions for job data search\n",
    "    1. define a function to get more data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8678018a",
   "metadata": {},
   "source": [
    "entries = range(0, 50, 10) # how many pages we want to retrieve the data, the second number determines how many pages \n",
    "def get_data_soup_list(job_title, city, entries):\n",
    "    soups = []\n",
    "    for entry in entries:\n",
    "        url= f\"https://www.indeed.com/jobs?q={job_title}&l={city}&start={entry}\"\n",
    "        soup = BeautifulSoup(requests.get(url).text, 'lxml')\n",
    "        soups.append(soup)\n",
    "    return soups;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6626aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "    2. define a function to retrieve data from indeed"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb6fb502",
   "metadata": {},
   "source": [
    "def extract_job_title_from_result(soup):\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs = {\"class\":\"job_seen_beacon\"}):\n",
    "        tbody = div.find(\"tbody\")  #go into the table body\n",
    "        trs = tbody.find_all('tr')\n",
    "        \n",
    "        for tr in trs:\n",
    "            td = tr.find('td', {\"class\":\"resultContent\"})\n",
    "\n",
    "            job_title = tr.find('h2').text\n",
    "            if job_title.startswith('new'):\n",
    "                \n",
    "                job_title = re.sub(\"^new\",\"\",job_title)\n",
    "            \n",
    "            company_name=tr.find('span', {\"class\":\"companyName\"}).text\n",
    "\n",
    "\n",
    "            company_location = tr.find('div',{\"class\":\"companyLocation\"}).text\n",
    "            \n",
    "\n",
    "\n",
    "            if tr.find('div',{\"class\":\"attribute_snippet\"}):\n",
    "                salary = tr.find('div',{\"class\":\"attribute_snippet\"}).text\n",
    "            else:\n",
    "                salary=None\n",
    "            if tr.find('a', {\"class\":\"turnstileLink companyOverviewLink\"}):\n",
    "                company_link = tr.find('a', {\"class\":\"turnstileLink companyOverviewLink\"})['href']\n",
    "            else:\n",
    "                company_link=None\n",
    "            \n",
    "            jobs.append((job_title, company_name, company_location, salary, company_link))\n",
    "\n",
    "    return jobs;\n",
    "extract_job_title_from_result(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3af43",
   "metadata": {},
   "source": [
    "    3. define a function that we can search different location and different job titles "
   ]
  },
  {
   "cell_type": "raw",
   "id": "74331487",
   "metadata": {},
   "source": [
    "entries = range(0, 50, 10) # how many pages we want to retrieve the data, the second number determines how many pages \n",
    "def get_data_list(job_title, city, entries):\n",
    "    jobs_list = []\n",
    "    soups=get_data_soup_list(job_title, city, entries)\n",
    "\n",
    "    for soup in soups:\n",
    "        jobs = extract_job_title_from_result(soup)\n",
    "        jobs_list.extend(jobs)\n",
    "\n",
    "    return jobs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4a152",
   "metadata": {},
   "source": [
    "    Use the function to find jobs about data scientists in Philadelphia."
   ]
  },
  {
   "cell_type": "raw",
   "id": "39f5477e",
   "metadata": {},
   "source": [
    "jobs_list = get_data_list(\"data scientist\", 'Philadelphia', entries)\n",
    "jobs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a82a2d",
   "metadata": {},
   "source": [
    "<div class=\"heading6 company_location tapItem-gutter\"><pre><span class=\"companyName\"><a class=\"turnstileLink companyOverviewLink\" data-tn-element=\"companyName\" href=\"/cmp/Alphasights-Ltd.\" rel=\"noopener\" target=\"_blank\">AlphaSights Ltd.</a>\n",
    "https://www.w3schools.com/html/html_tables.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60d367",
   "metadata": {},
   "source": [
    "     4. Write a function to store our data into MySQL\n",
    "reference https://pynative.com/python-mysql-insert-data-into-database-table/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2492b3ea",
   "metadata": {},
   "source": [
    "def store_data_into_MySQL(jobs_list):\n",
    "    import mysql.connector\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                                        database='DSCI511',\n",
    "                                        user='sammy',\n",
    "                                        password='dsci511')\n",
    "        mysql_insert_query = \"\"\"INSERT INTO Company (job_title,company_name, location, salary, url) VALUES (%s,%s,%s,%s,%s)\"\"\"\n",
    "    \n",
    "    \n",
    "        cursor = connection.cursor()\n",
    "        cursor.executemany(mysql_insert_query, jobs_list)\n",
    "        connection.commit()\n",
    "        print(cursor.rowcount, \"Record inserted successfully into MySQL table\")\n",
    "    \n",
    "    except mysql.connector.Error as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1538b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Record inserted successfully into MySQL table\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "store_data_into_MySQL(jobs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66d2af",
   "metadata": {},
   "source": [
    "     5. Retrieve data from MySQL"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a8d7764",
   "metadata": {},
   "source": [
    "def get_data_from_db(table_name):\n",
    "    try: \n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                                         database='DSCI511',\n",
    "                                         user='sammy',\n",
    "                                         password='dsci511')\n",
    "    \n",
    "        my_query = f\"SELECT * FROM {table_name}\"\n",
    "        cursor=connection.cursor()\n",
    "        cursor.execute(my_query)\n",
    "        records = cursor.fetchall()\n",
    "        for row in records:\n",
    "            print(\"ID: \", row[0])\n",
    "            if row[1]:\n",
    "                print(\"Job Title: \", row[1])\n",
    "            else:\n",
    "                print(\"Job title is not available.\")\n",
    "            if row[2]: \n",
    "                print(\"Company Name: \", row[2])\n",
    "            else:\n",
    "                print(\"Comapny Name is not available.\")\n",
    "            if row[3]:\n",
    "                print(\"Location: \", row[3])\n",
    "            else:\n",
    "                print(\"Location is not available.\")\n",
    "            if row[4]:\n",
    "                print('Salary: '+ row[4])\n",
    "            else:\n",
    "                print(\"Salary is not abailable.\")\n",
    "        connection.close()\n",
    "        cursor.close()\n",
    "    except mysql.connector.Error as error:\n",
    "            print(error)\n",
    "    finally: \n",
    "        if connection.is_connected():\n",
    "            connection.close()\n",
    "            cursor.close()\n",
    "            print(\"MySQL connection is closed\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c9a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_from_db(\"Company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9352419",
   "metadata": {},
   "source": [
    "    6. reading data from MySql using pandas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "785f64c2",
   "metadata": {},
   "source": [
    "def get_data_from_db_with_pandas(table_name):\n",
    "    import mysql.connector\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    my_connection = mysql.connector.connect(\n",
    "         host=\"localhost\",\n",
    "         user='sammy',\n",
    "        password='dsci511',\n",
    "        database='DSCI511'\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(f'SELECT * FROM {table_name}', my_connection)\n",
    "\n",
    "    my_connection.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f2e5655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Data Scientist - Delta One Strats</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York, NY+3 locations</td>\n",
       "      <td>None</td>\n",
       "      <td>/cmp/Morgan-Stanley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>Data Scientist II - Algorithmic Justice Specia...</td>\n",
       "      <td>American Civil Liberties Union</td>\n",
       "      <td>New York State+2 locations•Remote</td>\n",
       "      <td>$115,638 a year</td>\n",
       "      <td>/cmp/American-Civil-Liberties-Union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Alldus</td>\n",
       "      <td>New York, NY+2 locations•Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>The Trade Desk</td>\n",
       "      <td>New York, NY 10003 (Greenwich Village area)</td>\n",
       "      <td>None</td>\n",
       "      <td>/cmp/The-Trade-Desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>Research Scientist-Center for Data Science</td>\n",
       "      <td>New York University</td>\n",
       "      <td>New York, NY 10012 (Greenwich Village area)+4 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>/cmp/New-York-University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>132</td>\n",
       "      <td>Head of AI, Machine Learning, Data Science pro...</td>\n",
       "      <td>Xen.ai</td>\n",
       "      <td>Philadelphia, PA•Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>133</td>\n",
       "      <td>Chief Data Scientist Predictive Analytics</td>\n",
       "      <td>University of Pennsylvania Health System</td>\n",
       "      <td>Philadelphia, PA 19104 (University City area)</td>\n",
       "      <td>None</td>\n",
       "      <td>/cmp/University-of-Pennsylvania-Health-System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>134</td>\n",
       "      <td>Machine Learning Engineer - Opportunity for Wo...</td>\n",
       "      <td>VMware</td>\n",
       "      <td>Philadelphia, PA•Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>/cmp/Vmware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>135</td>\n",
       "      <td>AI Data Scientist</td>\n",
       "      <td>Resolution Life</td>\n",
       "      <td>West Chester, PA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>136</td>\n",
       "      <td>AI Engineer - Hux</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Philadelphia, PA 19103 (Rittenhouse area)</td>\n",
       "      <td>None</td>\n",
       "      <td>/cmp/Deloitte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          job_title  \\\n",
       "0    17                  Data Scientist - Delta One Strats   \n",
       "1    18  Data Scientist II - Algorithmic Justice Specia...   \n",
       "2    19                                     Data Scientist   \n",
       "3    20                                  Sr Data Scientist   \n",
       "4    21         Research Scientist-Center for Data Science   \n",
       "..  ...                                                ...   \n",
       "85  132  Head of AI, Machine Learning, Data Science pro...   \n",
       "86  133          Chief Data Scientist Predictive Analytics   \n",
       "87  134  Machine Learning Engineer - Opportunity for Wo...   \n",
       "88  135                                  AI Data Scientist   \n",
       "89  136                                  AI Engineer - Hux   \n",
       "\n",
       "                                company_name  \\\n",
       "0                             Morgan Stanley   \n",
       "1             American Civil Liberties Union   \n",
       "2                                     Alldus   \n",
       "3                             The Trade Desk   \n",
       "4                        New York University   \n",
       "..                                       ...   \n",
       "85                                    Xen.ai   \n",
       "86  University of Pennsylvania Health System   \n",
       "87                                    VMware   \n",
       "88                           Resolution Life   \n",
       "89                                  Deloitte   \n",
       "\n",
       "                                             location           salary  \\\n",
       "0                            New York, NY+3 locations             None   \n",
       "1                   New York State+2 locations•Remote  $115,638 a year   \n",
       "2                     New York, NY+2 locations•Remote             None   \n",
       "3         New York, NY 10003 (Greenwich Village area)             None   \n",
       "4   New York, NY 10012 (Greenwich Village area)+4 ...             None   \n",
       "..                                                ...              ...   \n",
       "85                            Philadelphia, PA•Remote             None   \n",
       "86      Philadelphia, PA 19104 (University City area)             None   \n",
       "87                            Philadelphia, PA•Remote             None   \n",
       "88                                   West Chester, PA             None   \n",
       "89          Philadelphia, PA 19103 (Rittenhouse area)             None   \n",
       "\n",
       "                                              url  \n",
       "0                             /cmp/Morgan-Stanley  \n",
       "1             /cmp/American-Civil-Liberties-Union  \n",
       "2                                            None  \n",
       "3                             /cmp/The-Trade-Desk  \n",
       "4                        /cmp/New-York-University  \n",
       "..                                            ...  \n",
       "85                                           None  \n",
       "86  /cmp/University-of-Pennsylvania-Health-System  \n",
       "87                                    /cmp/Vmware  \n",
       "88                                           None  \n",
       "89                                  /cmp/Deloitte  \n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_from_db_with_pandas('Company')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63023aa",
   "metadata": {},
   "source": [
    "Retrieve data from craigslist----using house data as sample:\n",
    "part 1: preparation----\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07fb9260",
   "metadata": {},
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389bb60",
   "metadata": {},
   "source": [
    "the fist url of our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4791dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://philadelphia.craigslist.org/d/for-sale/search/sss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a7eb6",
   "metadata": {},
   "source": [
    "1. define a function to get different locations we can use later"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed0eeaea",
   "metadata": {},
   "source": [
    "def get_locations(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    areas = soup.find('select', id='areaAbb')\n",
    "    locations = {}\n",
    "    for l in areas.find_all('option'):\n",
    "        locations.update({l.text:l.get('value')})\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e97b7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'philadelphia': 'philadelphia',\n",
       " 'albany, NY': 'albany',\n",
       " 'allentown': 'allentown',\n",
       " 'altoona': 'altoona',\n",
       " 'annapolis': 'annapolis',\n",
       " 'baltimore': 'baltimore',\n",
       " 'binghamton': 'binghamton',\n",
       " 'catskills': 'catskills',\n",
       " 'central NJ': 'cnj',\n",
       " 'charlottesville': 'charlottesville',\n",
       " 'cumberland val': 'chambersburg',\n",
       " 'delaware': 'delaware',\n",
       " 'eastern CT': 'newlondon',\n",
       " 'eastern shore': 'easternshore',\n",
       " 'eastern WV': 'martinsburg',\n",
       " 'elmira': 'elmira',\n",
       " 'finger lakes': 'fingerlakes',\n",
       " 'frederick': 'frederick',\n",
       " 'fredericksburg': 'fredericksburg',\n",
       " 'harrisburg': 'harrisburg',\n",
       " 'harrisonburg': 'harrisonburg',\n",
       " 'hartford': 'hartford',\n",
       " 'hudson valley': 'hudsonvalley',\n",
       " 'ithaca': 'ithaca',\n",
       " 'jersey shore': 'jerseyshore',\n",
       " 'lancaster, PA': 'lancaster',\n",
       " 'long island': 'longisland',\n",
       " 'new haven': 'newhaven',\n",
       " 'new york': 'newyork',\n",
       " 'norfolk': 'norfolk',\n",
       " 'north jersey': 'newjersey',\n",
       " 'northwest CT': 'nwct',\n",
       " 'oneonta': 'oneonta',\n",
       " 'poconos': 'poconos',\n",
       " 'reading': 'reading',\n",
       " 'richmond, VA': 'richmond',\n",
       " 'scranton': 'scranton',\n",
       " 'south jersey': 'southjersey',\n",
       " 'southern MD': 'smd',\n",
       " 'state college': 'pennstate',\n",
       " 'syracuse': 'syracuse',\n",
       " 'utica': 'utica',\n",
       " 'washington, DC': 'washingtondc',\n",
       " 'western mass': 'westernmass',\n",
       " 'western MD': 'westmd',\n",
       " 'williamsport': 'williamsport',\n",
       " 'winchester': 'winchester',\n",
       " 'york, PA': 'york'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_locations(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3418d",
   "metadata": {},
   "source": [
    "2. define a function to retrieve different subjects "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4b6a5f3",
   "metadata": {},
   "source": [
    "def get_subjects(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    catAbb = soup.find('select', id='catAbb')\n",
    "    catabbs = {}\n",
    "    for cat in catAbb.find_all('option'):\n",
    "        catabbs[cat.text]=cat.get('value')\n",
    "    return catabbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09502a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'community': 'ccc',\n",
       " 'events': 'eee',\n",
       " 'for sale': 'sss',\n",
       " 'gigs': 'ggg',\n",
       " 'housing': 'hhh',\n",
       " 'jobs': 'jjj',\n",
       " 'resumes': 'rrr',\n",
       " 'services': 'bbb'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_subjects(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ab6cc",
   "metadata": {},
   "source": [
    "3. Define a function to get the categories"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efbb3de0",
   "metadata": {},
   "source": [
    "def get_categories(city, catabb):\n",
    "  url = f\"https://{city}.craigslist.org/d/for-sale/search/{catabb}\"\n",
    "  \n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text,'html.parser')\n",
    "  category = soup.find('select', id = 'subcatAbb')\n",
    "  categories = {}\n",
    "  for c  in category.find_all('option'):\n",
    "      categories[c.text] = c.get('value')\n",
    "  return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48e72f",
   "metadata": {},
   "source": [
    "    find the Philadelphia area house categories"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc44b41d",
   "metadata": {},
   "source": [
    "categories = get_categories(\"Philadelphia\", \"hhh\")\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b59af",
   "metadata": {},
   "source": [
    "4. define a function that we can get data from different locations and differents categories:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7057d102",
   "metadata": {},
   "source": [
    "def get_housing_info(city, cat):\n",
    "    url = f\"https://{city}.craigslist.org/search/{cat}\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    table = soup.find('ul', id=\"search-results\")\n",
    "    lis = table.find_all('li',{\"class\":\"result-row\"})\n",
    "    houses = []\n",
    "    for li in lis:\n",
    "        if li.find('time'):\n",
    "            time = li.find('time').get('datetime')\n",
    "        else:\n",
    "            time=None\n",
    "        if li.find('a', {\"class\":\"result-title hdrlnk\"}):\n",
    "            \n",
    "            url = li.find('a', {\"class\":\"result-title hdrlnk\"})['href']\n",
    "        else:\n",
    "            url = None\n",
    "        if li.find('a', {\"class\":\"result-title hdrlnk\"}):\n",
    "            detail = li.find('a', {\"class\":\"result-title hdrlnk\"}).text\n",
    "        else:\n",
    "            detail = None\n",
    "        if li.find('span',{'class':\"result-price\"}):\n",
    "            \n",
    "            price = li.find('span',{'class':\"result-price\"}).text\n",
    "        else:\n",
    "            price = None\n",
    "        if li.find('span',{\"class\":\"result-hood\"}):\n",
    "            \n",
    "            location = li.find('span',{\"class\":\"result-hood\"}).text\n",
    "        else:\n",
    "            location = None\n",
    "        if li.find('span',{\"class\":\"housing\"}):\n",
    "            beds_fts = li.find('span',{\"class\":\"housing\"}).text\n",
    "        else:\n",
    "            beds_fts = None\n",
    "        houses+=[(detail, location, price, beds_fts, url)]\n",
    "    return houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0acd6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = get_housing_info('Philadelphia', 'reb')  # All house data from broker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e7b51",
   "metadata": {},
   "source": [
    "5. function to processing the raw data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6176f1ff",
   "metadata": {},
   "source": [
    "def processing_data(houses):\n",
    "    import re\n",
    "    new_houses =[]\n",
    "    for house in houses:\n",
    "        descript = house[0]\n",
    "        location = house[1]\n",
    "        if house[3]:\n",
    "            bedroom = re.search(r'\\d+br', house[3])\n",
    "            if bedroom:\n",
    "                bedroom = bedroom.group(0)\n",
    "            else:\n",
    "                bedroom='NA'\n",
    "            room_sqr_ft = re.search(r'\\d+ft', house[3])\n",
    "            if room_sqr_ft:\n",
    "                room_sqr_ft = re.search(r'\\d+ft', house[3]).group(0)[:-2]\n",
    "            else:\n",
    "                room_sqr_ft = 'NA'\n",
    "        if house[2]:\n",
    "            price = house[2].replace('$',\"\").replace(',',\"\")\n",
    "        else:\n",
    "            price = 0\n",
    "    \n",
    "        new_houses +=[(descript,location, bedroom, room_sqr_ft,price)]   \n",
    "    return new_houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fec8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_houses = processing_data(houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a0ab17",
   "metadata": {},
   "source": [
    "6. Function to store the data into database:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfb472f8",
   "metadata": {},
   "source": [
    "def store_data_into_MySQL(house_list):\n",
    "    import mysql.connector\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                                        database='DSCI511',\n",
    "                                        user='sammy',\n",
    "                                        password='dsci511')\n",
    "        mysql_insert_query = \"\"\"INSERT INTO Houses (description,location,bedroom, room_sqr_ft, price) VALUES (%s,%s,%s,%s,%s)\"\"\"\n",
    "    \n",
    "    \n",
    "        cursor = connection.cursor()\n",
    "        cursor.executemany(mysql_insert_query, house_list)\n",
    "        connection.commit()\n",
    "        print(cursor.rowcount, \"Record inserted successfully into MySQL table\")\n",
    "    \n",
    "    except mysql.connector.Error as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ae61801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 Record inserted successfully into MySQL table\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "store_data_into_MySQL(new_houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807518d9",
   "metadata": {},
   "source": [
    "7. reading data from MySql using pandas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d80a4d0",
   "metadata": {},
   "source": [
    "def get_data_from_db_with_pandas(table_name):\n",
    "    import mysql.connector\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    my_connection = mysql.connector.connect(\n",
    "         host=\"localhost\",\n",
    "         user='sammy',\n",
    "        password='dsci511',\n",
    "        database='DSCI511'\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(f'SELECT * FROM {table_name}', my_connection)\n",
    "\n",
    "    my_connection.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d86f53c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>room_sqr_ft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Finest ranch style living with ultra privacy</td>\n",
       "      <td>(Minutes away  )</td>\n",
       "      <td>3br</td>\n",
       "      <td>NA</td>\n",
       "      <td>995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Prime Princeton Estate</td>\n",
       "      <td>(Princeton  )</td>\n",
       "      <td>3br</td>\n",
       "      <td>NA</td>\n",
       "      <td>999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>EST. AUTO REPAIR on 5.62 Acres close to area b...</td>\n",
       "      <td>(Cape May Court House  )</td>\n",
       "      <td>3br</td>\n",
       "      <td>NA</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Vacant Lot Near Wildwood Beaches!...Residentia...</td>\n",
       "      <td>(Rio Grande  )</td>\n",
       "      <td>3br</td>\n",
       "      <td>NA</td>\n",
       "      <td>119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great Cash Flow on Turnkey 5 Unit Year Round B...</td>\n",
       "      <td>(Wildwood Crest  )</td>\n",
       "      <td>6br</td>\n",
       "      <td>NA</td>\n",
       "      <td>675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116</td>\n",
       "      <td>MONTCO Cash Buyer Alert!!</td>\n",
       "      <td>(Norristown  )</td>\n",
       "      <td>4br</td>\n",
       "      <td>1530</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>Gem In The Rough</td>\n",
       "      <td>(West Oak Lane  )</td>\n",
       "      <td>3br</td>\n",
       "      <td>1280</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>4 bedroom home in the heart of Royersford</td>\n",
       "      <td>(Royersford, PA  )</td>\n",
       "      <td>4br</td>\n",
       "      <td>2112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>Quiet Neighborhood Gem</td>\n",
       "      <td>(Pottstown, PA  )</td>\n",
       "      <td>4br</td>\n",
       "      <td>1081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>Large Private Lot</td>\n",
       "      <td>(Pottstown, PA  )</td>\n",
       "      <td>3br</td>\n",
       "      <td>1861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        description  \\\n",
       "0      1       Finest ranch style living with ultra privacy   \n",
       "1      2                             Prime Princeton Estate   \n",
       "2      3  EST. AUTO REPAIR on 5.62 Acres close to area b...   \n",
       "3      4  Vacant Lot Near Wildwood Beaches!...Residentia...   \n",
       "4      5  Great Cash Flow on Turnkey 5 Unit Year Round B...   \n",
       "..   ...                                                ...   \n",
       "115  116                          MONTCO Cash Buyer Alert!!   \n",
       "116  117                                   Gem In The Rough   \n",
       "117  118          4 bedroom home in the heart of Royersford   \n",
       "118  119                             Quiet Neighborhood Gem   \n",
       "119  120                                  Large Private Lot   \n",
       "\n",
       "                      location bedroom room_sqr_ft   price  \n",
       "0             (Minutes away  )     3br          NA  995000  \n",
       "1                (Princeton  )     3br          NA  999999  \n",
       "2     (Cape May Court House  )     3br          NA  299900  \n",
       "3               (Rio Grande  )     3br          NA  119900  \n",
       "4           (Wildwood Crest  )     6br          NA  675000  \n",
       "..                         ...     ...         ...     ...  \n",
       "115             (Norristown  )     4br        1530   65000  \n",
       "116          (West Oak Lane  )     3br        1280  135000  \n",
       "117         (Royersford, PA  )     4br        2112       0  \n",
       "118          (Pottstown, PA  )     4br        1081       0  \n",
       "119          (Pottstown, PA  )     3br        1861       0  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_from_db_with_pandas(\"Houses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2287445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52186e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
